{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regulation-heating",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-corruption",
   "metadata": {},
   "source": [
    "This is the text classification of a popular dataset <b>\"20 newsgroups\"</b>.\n",
    "<br>Here, I'm using <b>Multinomial NaiveBayes</b> which is quite powerful and fast when it comes to text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "behind-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from IPython.display import clear_output # to get realtime updations in model making"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-fifty",
   "metadata": {},
   "source": [
    "## Self Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-music",
   "metadata": {},
   "source": [
    "Dataset - http://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "formal-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for reading dataset files\n",
    "def readDatasetFiles():\n",
    "    X = []\n",
    "    Y = []\n",
    "    total_files = 0\n",
    "    for category in os.listdir(r\"./20_newsgroups\"):\n",
    "        for document in os.listdir(r\"./20_newsgroups/\" + category):\n",
    "            total_files += 1\n",
    "    total_files_readed = 0\n",
    "    for category in os.listdir(r\"./20_newsgroups\"):\n",
    "        for document in os.listdir(r\"./20_newsgroups/\" + category):\n",
    "            clear_output(wait = True)\n",
    "            print('Total Files Readed:', total_files_readed, 'Out of', total_files)\n",
    "            with open(\"./20_newsgroups/\"+category+\"/\"+document ,\"r\") as file:\n",
    "                X.append((document, file.read()))\n",
    "                Y.append(category)\n",
    "            total_files_readed += 1\n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-norway",
   "metadata": {},
   "source": [
    "### Tokenization of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-taylor",
   "metadata": {},
   "source": [
    "<b>\"Stopwords\"</b>, these are the words which are present in almost every document.<br>So it is better to remove these from the dataset as this will not be useful while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "constitutional-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word=[\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\n",
    "\"by\",\"could\",\"did\",\"do\",\"does\",\"doing\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"has\",\"have\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\n",
    "\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\n",
    "\"more\",\"most\",\"my\",\"myself\",\"nor\",\"of\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"she\",\n",
    "\"she'd\",\"she'll\",\"she's\",\"should\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\n",
    "\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"we\",\"we'd\",\n",
    "\"we'll\",\"we're\",\"we've\",\"were\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\n",
    "\"would\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sticky-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split a sentence into bag of words from every non-alphanumeric character or a group of same\n",
    "def tokenize(x):\n",
    "    tokens = re.split(r'\\W+', x.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "boxed-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make a dictionary of all words which are present in training dataset\n",
    "def makeDictionary(x_train):\n",
    "    dictionary = {}\n",
    "    total_training_data = len(x_train)\n",
    "    features_extracted_from_training_data = 0\n",
    "    for x in x_train: # iterate through all the training datapoints\n",
    "        clear_output(wait = True)\n",
    "        print('Features Extracted From', features_extracted_from_training_data, 'Out of', total_training_data, 'Training Data')\n",
    "        x_tokens = tokenize(x[1])\n",
    "        for token in x_tokens:\n",
    "            # purifying the dictionary from stopwords or words which contains a non-alphabet character, etc\n",
    "            if not(token.isalpha()) or token in stop_word or len(token) <= 2:\n",
    "                continue\n",
    "            if token in dictionary:\n",
    "                dictionary[token] += 1\n",
    "            else:\n",
    "                dictionary[token] = 1\n",
    "        features_extracted_from_training_data += 1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "civic-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to select top few words(as features) from the dictionary which has the max frequency in training dataset\n",
    "def prepareModelFeatures(x_train):\n",
    "    dictionary = makeDictionary(x_train)\n",
    "    sorted_dictionary = sorted(dictionary.items(), key = lambda item: item[1], reverse = True)\n",
    "    vocabulary = [i[0] for i in sorted_dictionary]\n",
    "    features = vocabulary[:3000]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-vancouver",
   "metadata": {},
   "source": [
    "After preparing the features, lets say n features for the model training,\n",
    "### Preprocessing of training and testing data\n",
    "Make a dataframe which contains n features as its column names and its rows as training datapoints word count\n",
    "<br>Each row has n length. And the ith column of each row contains the count of the word(ith feature) in that particular datapoint\n",
    "<br>And do the same with the testing datapoints, but the features used will be same as the training datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "specified-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preprocessing of the training data\n",
    "def preprocessTrainingData(x_train):\n",
    "    features = prepareModelFeatures(x_train) # get features from training data\n",
    "    x_train_dataset = np.zeros([len(x_train), len(features)], int)\n",
    "    total_training_data = len(x_train)\n",
    "    proccessed_training_data = 0\n",
    "    for i in range(len(x_train)): # iterating through each datapoint\n",
    "        clear_output(wait = True)\n",
    "        print('Training Data Processed on Obtained Features:', proccessed_training_data, 'Out of', total_training_data)\n",
    "        x = x_train[i][1]\n",
    "        # count each feature in the datapoint and put it in the column of corresponding feature in the current row\n",
    "        x_tokens = re.split(r'\\W+', x.lower())\n",
    "        for token in x_tokens:\n",
    "            if token in features:\n",
    "                x_train_dataset[i][features.index(token)] += 1\n",
    "        proccessed_training_data += 1\n",
    "    return (x_train_dataset, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "attractive-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preprocessing of the training data\n",
    "def preprocessTestingData(x_test, features):\n",
    "    x_test_dataset = np.zeros([len(x_test), len(features)], int)\n",
    "    total_testing_data = len(x_test)\n",
    "    proccessed_testing_data = 0\n",
    "    for i in range(len(x_test)): # iterating through each datapoint\n",
    "        clear_output(wait = True)\n",
    "        print('Testing Data Processed on Obtained Features:', proccessed_testing_data, 'Out of', total_testing_data)\n",
    "        x = x_test[i][1]\n",
    "        # count each feature in the datapoint and put it in the column of corresponding feature in the current row\n",
    "        x_tokens = re.split(r'\\W+', x.lower())\n",
    "        for token in x_tokens:\n",
    "            if token in features:\n",
    "                x_test_dataset[i][features.index(token)] += 1\n",
    "        proccessed_testing_data += 1\n",
    "    return x_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-hunger",
   "metadata": {},
   "source": [
    "### Model Making"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-ferry",
   "metadata": {},
   "source": [
    "fit function - makes a dictionary which has its keys as model classes and values as another dictionary which has its keys as features and values as the feature count in the training data of class(key of previous dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "italian-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fit function\n",
    "def fit(x_train, y_train, features):\n",
    "    result = {}\n",
    "    classes = list(set(y_train))\n",
    "    for current_class in classes:\n",
    "        result[current_class] = {}\n",
    "        current_x_train = x_train[y_train == current_class]\n",
    "        current_y_train = y_train[y_train == current_class]\n",
    "        result[current_class]['total_count'] = len(current_y_train)\n",
    "        for i in range(len(features)):\n",
    "            current_feature_value = current_x_train[:, i]\n",
    "            result[current_class][features[i]] = np.sum(current_feature_value)\n",
    "        result[current_class]['total_words'] = np.sum(list(result[current_class].values()))\n",
    "    result['total_data'] = len(y_train)\n",
    "    result['dictionary'] = features\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-sunrise",
   "metadata": {},
   "source": [
    "probability function - calculates the probability of a particular class using bayes theorem and laplace correction\n",
    "<br><br>bayes theorem:<br>\n",
    "probability of particular class = $\\prod_i (\\frac{count of ith feature in that class}{count of all features in that class}) * \\frac{count of that class}{count of all classes}$ Here ith feature is every word in the test data \n",
    "<br><br>laplace correction:<br>\n",
    "add 1 in the numerator and add count of all features in denominator of probability of a particular feature while calculating for any class to avoid zero probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "copyrighted-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate probability of a particular class for a particular test data\n",
    "def probability(clf, x, current_class):\n",
    "    # used log because value may be lower than 1 which then on multiplication may creates problem\n",
    "    output = np.log(clf[current_class]['total_count']) - np.log(clf['total_data'])\n",
    "    for i in range(len(x)):\n",
    "        current_datapoint = x[i]\n",
    "        current_feature = clf['dictionary'][i]\n",
    "        count_current_feature_in_current_class = clf[current_class][current_feature] + 1\n",
    "        count_all_features_in_current_class = clf[current_class]['total_words'] + (len(clf[current_class].keys()) - 1)\n",
    "        current_feature_probability_in_current_class = np.log(count_current_feature_in_current_class) - np.log(count_all_features_in_current_class)\n",
    "        for j in range(current_datapoint):\n",
    "            output += current_feature_probability_in_current_class\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thermal-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to identify the best class which has the max probability for a particular test data\n",
    "def predict_single_class(clf, x):\n",
    "    classes = clf.keys()\n",
    "    current_class = 0\n",
    "    best_p = -1000\n",
    "    best_class = -1\n",
    "    first_run = True\n",
    "    for current_class in classes:\n",
    "        if (current_class == \"total_data\" or current_class == \"dictionary\"):\n",
    "            continue\n",
    "        p_current_class = probability(clf, x, current_class)\n",
    "        if (first_run or p_current_class > best_p): # Obtaining the class with higher probability\n",
    "            best_p = p_current_class\n",
    "            best_class = current_class\n",
    "        first_run = False\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "palestinian-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict function\n",
    "def predict(clf, x_test_dataset):\n",
    "    y_pred = []\n",
    "    total_testing_data = len(x_test_dataset)\n",
    "    total_tested_data = 0\n",
    "    for x in x_test_dataset:\n",
    "        predicted_class = predict_single_class(clf, x)\n",
    "        clear_output(wait = True)\n",
    "        print('Model Tested on', total_tested_data, 'Out of', total_testing_data, 'Testing Data')\n",
    "        y_pred.append(predicted_class)\n",
    "        total_tested_data += 1\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-cycle",
   "metadata": {},
   "source": [
    "#### Running all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "thirty-experience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training & Testing Dataset Processed and Ready\n"
     ]
    }
   ],
   "source": [
    "X, Y = readDatasetFiles()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "x_train_dataset, features = preprocessTrainingData(x_train)\n",
    "y_train_dataset = np.array(y_train)\n",
    "x_test_dataset = preprocessTestingData(x_test, features)\n",
    "y_test_dataset = np.array(y_test)\n",
    "clear_output(wait = True)\n",
    "print('Training & Testing Dataset Processed and Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "posted-highway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "clf = fit(x_train_dataset, y_train_dataset, features)\n",
    "print('Training Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Tested on 4000 Out of 5000 Testing Data\n"
     ]
    }
   ],
   "source": [
    "y_pred_MultinomialNB = predict(clf, x_test_dataset)\n",
    "clear_output(wait = True)\n",
    "\n",
    "# model report\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test_dataset, y_pred_MultinomialNB))\n",
    "print(\"Confusion Matrix\")\n",
    "labels = np.unique(y_test_dataset)\n",
    "cm = confusion_matrix(y_test_dataset, y_pred_MultinomialNB, labels = labels)\n",
    "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "plt.figure(figsize = (24, 16))\n",
    "sns.set(font_scale = 1.6)\n",
    "ax = sns.heatmap(df_cm, annot = True, cmap = \"Blues\", annot_kws = {'size': 14}, fmt = 'g')\n",
    "ax.set_ylim(20.0, 0.0)\n",
    "plt.show()\n",
    "print()\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test_dataset, y_pred_MultinomialNB) * 100, \"%\", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-water",
   "metadata": {},
   "source": [
    "## Comparison of the above model with the sklearn inbuild model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "sklearn_clf = MultinomialNB()\n",
    "sklearn_clf.fit(x_train_dataset, y_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sklearn_MultinomialNB = sklearn_clf.predict(x_test_dataset)\n",
    "\n",
    "# model report\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test_dataset, y_pred_sklearn_MultinomialNB))\n",
    "print(\"Confusion Matrix\")\n",
    "labels = np.unique(y_test_dataset)\n",
    "cm = confusion_matrix(y_test_dataset, y_pred_sklearn_MultinomialNB, labels = labels)\n",
    "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "plt.figure(figsize = (24, 16))\n",
    "sns.set(font_scale = 1.6)\n",
    "ax = sns.heatmap(df_cm, annot = True, cmap = \"Blues\", annot_kws = {'size': 14}, fmt = 'g')\n",
    "ax.set_ylim(20.0, 0.0)\n",
    "plt.show()\n",
    "print()\n",
    "print(\"Accuracy Score:\", end = \" \")\n",
    "print(accuracy_score(y_test_dataset, y_pred_sklearn_MultinomialNB) * 100, \"%\", sep=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
